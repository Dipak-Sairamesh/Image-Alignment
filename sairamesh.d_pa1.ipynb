{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fa1e85",
   "metadata": {},
   "source": [
    "# Programming assignment 1: Aligning Prokudin-Gorskii images\n",
    "(adapted from Alexei Efros@UC Berkeley and Subhransu Maji@UMass Amherst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8ff3e",
   "metadata": {},
   "source": [
    "<font size=\"4\">Sergei Mikhailovich Prokudin-Gorskii (1863-1944) was a man well ahead of his time. Convinced, as early as 1907, that color photography was the wave of the future, he won Tzar’s special permission to travel across the vast Russian Empire and take color photographs of everything he saw including the only color portrait\n",
    "of Leo Tolstoy. And he really photographed everything: people, buildings, landscapes, railroads, bridges...\n",
    "thousands of color pictures! His idea was simple: record three exposures of every scene onto a glass plate\n",
    "using a red, a green, and a blue filter. Never mind that there was no way to print color photographs until\n",
    "much later – he envisioned special projectors to be installed in ”multimedia” classrooms all across Russia\n",
    "where the children would be able to learn about their vast country. Alas, his plans never materialized: he\n",
    "left Russia in 1918, right after the revolution, never to return again. Luckily, his RGB glass plate negatives,\n",
    "capturing the last years of the Russian Empire, survived and were purchased in 1948 by the Library of\n",
    "Congress. The LoC has recently digitized the negatives and made them available on-line.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3a87d",
   "metadata": {},
   "source": [
    "<img src='meta_data/example-Prokudin-Gorskii.png' height='1200'/>\n",
    "<font size=\"3\">Figure 1: Example image from the Prokudin-Gorskii collection. On the left are the three images captured\n",
    "individually. On the right is a reconstructed color photograph. Note the colors are in B, G, R order from the\n",
    "top to bottom (and not R, G, B)!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a3230e",
   "metadata": {},
   "source": [
    "<font size=\"4\">Your goal is to take photographs of each plate and generate a color image by aligning them (as shown in the right of Figure 1). The easiest way to align the plates is to exhaustively search over a window of possible displacements\n",
    "(say [-15,15] pixels), score each one using some image matching metric, and take the displacement with\n",
    "the best score.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28558894",
   "metadata": {},
   "source": [
    "## Submission format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764df143",
   "metadata": {},
   "source": [
    "* <your_nu_username>_pa1.ipynb (finished this file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535fda3",
   "metadata": {},
   "source": [
    "## Note:\n",
    "The OpenCV library is only used to load and save images. You are not allowed to use any OpenCV's built-in functions unless otherwise noted as in the task 5. The Numpy library is sufficient to finish this assignment. \n",
    "\n",
    "Do not install any additional packages inside the conda environment. The TAs will use the same environment as defined in the config files we provide you, so anything that’s not in there by default will probably cause your code to break during grading. Failure to follow any of these instructions will lead to point deductions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac9121",
   "metadata": {},
   "source": [
    "## Module import and image reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5597f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook autoload module setting\n",
    "# see https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.close('all')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single gray-scale image\n",
    "raw_im = cv2.imread('data/00153v.jpg', cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "print(raw_im.shape)\n",
    "print(raw_im.min(), raw_im.max())\n",
    "# the output of these two print calls should be\n",
    "# (1024, 394)\n",
    "# 0 255\n",
    "\n",
    "# let's do a simple visualization\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(raw_im, cmap='gray', vmin=0, vmax=255)\n",
    "# you should be able to see a grayscale image showing a person sitting there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f9afa8",
   "metadata": {},
   "source": [
    "## Programming assignment starts here (100 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bebff9",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"red\">**task 1: split the raw image into three parts (5 points)**</font><br><br>\n",
    "<font size=\"4\"> We can see there are three photos shown above. These photos represent images captured with a blue, green, and red filter. The first task you need to do is to split the raw image vertically into three parts. \n",
    "Note the photos are in B, G, R order from the top to bottom (and not R, G, B)!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_raw_image(raw_im):\n",
    "    # implement the function to split the raw_im vertically into three images\n",
    "    # corresponding to the B, G, R channel, respectively\n",
    "    # three channels should have the same spatial dimensions\n",
    "    # replace the dummpy implmentation with your own\n",
    "\n",
    "    image_height = raw_im.shape[0]\n",
    "    individual_image_height = int(image_height/3)\n",
    "    im_b = raw_im[0 : individual_image_height] # First part of image\n",
    "    im_g = raw_im[individual_image_height : 2*individual_image_height] # Second part of image\n",
    "    im_r = raw_im[2*individual_image_height : 3*individual_image_height] # Third part of image\n",
    "\n",
    "    return im_r, im_g, im_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be09e77",
   "metadata": {},
   "source": [
    "### sanity check: let's visualize the split results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6341de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do a visualization to see if they look\n",
    "im_r, im_g, im_b = split_raw_image(raw_im)\n",
    "print(im_r.shape, im_g.shape, im_b.shape)\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "\n",
    "# channel R\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax1.imshow(im_r, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "# channel G\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "ax2.imshow(im_g, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "# channel B\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "ax3.imshow(im_b, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd339a5",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"red\">**task 2: implement a function that tells us how close two images are (10 points)**</font><br><br>\n",
    "<font size=\"4\">There is a number of possible metrics that one could use to score how well the images match. We are going to use the normalized cross-correlation (NCC), which is simply a dot product between two normalized vectors. Specifically, given two channel photots, we treat each of them as a vector, normalize each of them with L2 norm, and compute the dot product between them.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c72053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(ref_im, input_im):\n",
    "    # calculate and return the ncc between the ref_im and input_im\n",
    "    # sanity check\n",
    "    assert len(ref_im.shape) == 2\n",
    "    assert len(input_im.shape) == 2\n",
    "    \n",
    "    # replace the dummpy implmentation with your own\n",
    "\n",
    "    correlation = np.sum(ref_im * input_im) # Numerator\n",
    "    norm = np.sqrt(np.sum(ref_im * ref_im)) * np.sqrt(np.sum(input_im * input_im)) # Denominator\n",
    "    ncc = correlation / norm\n",
    "    \n",
    "    return ncc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34b74a4",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"red\">**task 3: find the best displacements between two channels to align one to the other (30 points)**</font><br><br>\n",
    "<font size=\"4\">We need to consider displacements in both the horizontal and vertical directions.</font> \n",
    "\n",
    "<font size=\"4\">**Hint 1**: Use `np.roll()` to offset the channels while keeping the same dimensions among them. **Note that the roll is circular** that means if you roll the image to the left, the left edge goes to the right. This also happens to the vertical roll. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_displacement(im1, im2, x_disp=(-15, 15), y_disp=(-15, 15)):\n",
    "    # im1: one channel image\n",
    "    # im2: the other channel image\n",
    "    # x_disp: minimum and maximum of the horizontal displacement\n",
    "    # y_disp: minimum and maximum of the vertical displacement\n",
    "    # replace the dummy implmentation with your own\n",
    "    best_x_disp, best_y_disp = 0, 0\n",
    "    maximum_score = normalized_cross_correlation(im1, im2)\n",
    "    # Iterate through x and y axes to find the x and y displacements with best NCC\n",
    "    for i in range(x_disp[0], x_disp[1]) :\n",
    "        for j in range(y_disp[0], y_disp[1]) :\n",
    "            rolled_image = np.roll(im2, i, axis=1) # Roll image in first axis\n",
    "            shifted_image = np.roll(rolled_image, j, axis=0) # Roll image in second axis\n",
    "            score = normalized_cross_correlation(im1, shifted_image)\n",
    "            if score > maximum_score:\n",
    "                maximum_score = score\n",
    "                best_x_disp = i\n",
    "                best_y_disp = j\n",
    "\n",
    "    return best_x_disp, best_y_disp    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822330f",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"red\">**task 4: align and combine three channels together to get a colorful image (20 points)**</font><br><br>\n",
    "<font size=\"4\">Finally, we fix the R (red) channel and align the rest two to it and combine them together to get a colorful image. Your implementation shouldn't be too slow. Our reference implementation takes about 0.75s on our computer with an Intel® Xeon(R) E-2276M CPU @ 2.80GHz CPU.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_image(im_r, im_g, im_b, disp_search_func=get_best_displacement):\n",
    "    # im_r: R channel\n",
    "    # im_g: G channel\n",
    "    # im_b: B channel\n",
    "    # output the colorful image and the best displacement found\n",
    "\n",
    "    # note that disp_search_func is a callable function\n",
    "    # you can directly use it as\n",
    "    # best_x_disp, best_y_disp = disp_search_func(im_g, im_b)\n",
    "    \n",
    "    # replace this dummy implementation with yours\n",
    "\n",
    "    # Best displacements for G\n",
    "    best_g_disp = disp_search_func(im_r, im_g)\n",
    "    im_g_rolled = np.roll(im_g, best_g_disp[0], axis=1)\n",
    "    im_g_shifted = np.roll(im_g_rolled, best_g_disp[1], axis=0)\n",
    "    # Best displacements for B\n",
    "    best_b_disp = disp_search_func(im_r, im_b)\n",
    "    im_b_rolled = np.roll(im_b, best_b_disp[0], axis=1)\n",
    "    im_b_shifted = np.roll(im_b_rolled, best_b_disp[1], axis=0)\n",
    "    # Stacking the three parts in RGB order\n",
    "    im_color = np.stack(np.asarray([im_r, im_g_shifted, im_b_shifted]), axis = 2)\n",
    "\n",
    "    return im_color, best_g_disp, best_b_disp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db480043",
   "metadata": {},
   "source": [
    "### let's visualize the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "im_color, best_g_disp, best_b_disp = get_color_image(im_r, im_g, im_b)\n",
    "toc = time.time()\n",
    "print('G channel, x-disp: {}, y-disp: {}'.format(best_g_disp[0], best_g_disp[1]))\n",
    "print('B channel, x-disp: {}, y-disp: {}'.format(best_b_disp[0], best_b_disp[1]))\n",
    "print('Elapsed time: {:.3f}s'.format(toc - tic))\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(im_color.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694372ce",
   "metadata": {},
   "source": [
    "\n",
    "### if you are satisfied with your implmentation, run them on a batch of images, and save the results\n",
    "<font size=\"4\">Note if the `output` directory exists, results there will be overwritten.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "im_paths = sorted(glob.glob('data/*.jpg'))\n",
    "for im_path_i in im_paths:\n",
    "    im_name_i = os.path.basename(im_path_i)\n",
    "    raw_im_i = cv2.imread(im_path_i, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    tic = time.time()\n",
    "    im_r, im_g, im_b = split_raw_image(raw_im_i)\n",
    "    im_color, best_g_disp, best_b_disp = get_color_image(im_r, im_g, im_b)\n",
    "    toc = time.time()\n",
    "    cv2.imwrite(os.path.join(output_dir, im_name_i), im_color.astype(np.uint8)[:, :, ::-1])\n",
    "    print(im_name_i)\n",
    "    print('G channel, x-disp: {}, y-disp: {}'.format(best_g_disp[0], best_g_disp[1]))\n",
    "    print('B channel, x-disp: {}, y-disp: {}'.format(best_b_disp[0], best_b_disp[1]))\n",
    "    print('Elapsed time: {:.3f}s'.format(toc - tic))\n",
    "    print('===\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f83e9e",
   "metadata": {},
   "source": [
    "<font size=\"4\" color=\"red\">**task 5: coarse-to-fine alignment using image pyramid (35 points)**</font><br><br>\n",
    "<font size=\"4\">Searching over large displacements can be slow especially for high-resolution images. An efficient solution is to resize images to form two image pyramids, where each pyramid level downsamples the image in the previous level by factor 2. The idea is that we search for the best dispalcements on the smallest resolution and gradually refine the dispalcements in the larger resolutions.</font>\n",
    "\n",
    "<font size=\"4\">**Hint 1**: Suppose in a coarse image pyramid level k, the best displacements we find is (dx, dy). What should such displacments be in the finer image pyramid level k-1? Recall the spatial resolution of k-level is half of the resolution of (k-1)-level.</font>\n",
    "\n",
    "<font size=\"4\">**Hint 2**: You can use the `cv2.resize()` function to downsample an image. There is no need to apply the Gauss blurring before the resizing.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_displacement_pyramid(im1, im2, x_disp=(-15, 15), y_disp=(-15, 15), num_pyramid=4):\n",
    "    # compared to the get_best_displacement function, here we have an extra input\n",
    "    # num_pyramid denotes the number of pyramid level to use\n",
    "    \n",
    "    # replace the dummy implmentation with your own\n",
    "\n",
    "    if num_pyramid >= 0:\n",
    "        # Resizing images by factor of 2\n",
    "        num_pyramid -= 1\n",
    "        im1_resized = cv2.resize(im1, None, fx=0.5, fy=0.5)\n",
    "        im2_resized = cv2.resize(im2, None, fx=0.5, fy=0.5)\n",
    "\n",
    "        displacement = get_best_displacement(im1_resized, im2_resized, x_disp, y_disp)\n",
    "        # Multiplying x and y displacements by 2 to accommodate for resizing\n",
    "        shift = displacement * 2\n",
    "        # Roll image in both axes\n",
    "        im2 = np.roll(im2, shift[0], axis=1)\n",
    "        im2 = np.roll(im2, shift[1], axis=0)\n",
    "        # Finding the displacements in the original level\n",
    "        shift_level = get_best_displacement(im1, im2, x_disp, y_disp)\n",
    "        # Updating displacements with respect to original resolution\n",
    "        best_x_disp = shift[0] + shift_level[0]\n",
    "        best_y_disp = shift[1] + shift_level[1]\n",
    "        get_best_displacement_pyramid(im1_resized, im2_resized, x_disp, y_disp, num_pyramid)\n",
    "\n",
    "        return best_x_disp, best_y_disp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae51840",
   "metadata": {},
   "source": [
    "### Let's run the efficient implementation on all images again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f701656",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output-pyramid'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "im_paths = sorted(glob.glob('data/*.jpg'))\n",
    "for im_path_i in im_paths:\n",
    "    im_name_i = os.path.basename(im_path_i)\n",
    "    raw_im_i = cv2.imread(im_path_i, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    tic = time.time()\n",
    "    im_r, im_g, im_b = split_raw_image(raw_im_i)\n",
    "    im_color, best_g_disp, best_b_disp = get_color_image(im_r, im_g, im_b, get_best_displacement_pyramid)\n",
    "    toc = time.time()\n",
    "    cv2.imwrite(os.path.join(output_dir, im_name_i), im_color.astype(np.uint8)[:, :, ::-1])\n",
    "    print(im_name_i)\n",
    "    print('G channel, x-disp: {}, y-disp: {}'.format(best_g_disp[0], best_g_disp[1]))\n",
    "    print('B channel, x-disp: {}, y-disp: {}'.format(best_b_disp[0], best_b_disp[1]))\n",
    "    print('Elapsed time: {:.3f}s'.format(toc - tic))\n",
    "    print('===\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be178e",
   "metadata": {},
   "source": [
    "### Let's have some fun to test the efficient solution on a giant image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5cb4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_im = cv2.imread('data/emir.tif', cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "print(raw_im.shape)\n",
    "\n",
    "tic = time.time()\n",
    "im_r, im_g, im_b = split_raw_image(raw_im)\n",
    "im_color, best_g_disp, best_b_disp = get_color_image(im_r, im_g, im_b, get_best_displacement_pyramid)\n",
    "toc = time.time()\n",
    "print('G channel, x-disp: {}, y-disp: {}'.format(best_g_disp[0], best_g_disp[1]))\n",
    "print('B channel, x-disp: {}, y-disp: {}'.format(best_b_disp[0], best_b_disp[1]))\n",
    "print('Elapsed time: {:.3f}s'.format(toc - tic))\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(im_color.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
